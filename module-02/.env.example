# Ollama Configuration
# Ensure Ollama is running locally (default: http://localhost:11434)
# OLLAMA_BASE_URL=http://localhost:11434

# Optional: Model configuration
# MODEL_NAME=qwen3:8b
# TEMPERATURE=0
